{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cebb637",
   "metadata": {},
   "source": [
    "# How to use OpenCV to segment the cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f678c444",
   "metadata": {},
   "source": [
    "## Package inclusion for Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "149ab35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a48a431",
   "metadata": {},
   "source": [
    "## Read the image from a file on the disk and return a new matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10e14be",
   "metadata": {},
   "source": [
    "![Input image.](../cells_greyscale.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce50136a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"../cells_greyscale.png\", cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e440c334",
   "metadata": {},
   "source": [
    "## Check for errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ab5398e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for failure\n",
    "if image is None: \n",
    "    raise Exception(\"Could not open or find the image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b953f189",
   "metadata": {},
   "source": [
    "## Compute its histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93434f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_size = 255\n",
    "\n",
    "histogram = cv2.calcHist(image, # Image to analyse\n",
    "                         [0], # Number of channels\n",
    "                         None, # Mask\n",
    "                         [histogram_size], # Number of bins\n",
    "                         [0, 255]) # Ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66964a0",
   "metadata": {},
   "source": [
    "## Display the image in a window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "646176b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow(\"Cells\", cv2.WINDOW_GUI_EXPANDED) # Create a window\n",
    "cv2.imshow(\"Cells\", image) # Show our image inside the created window."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f606d8",
   "metadata": {},
   "source": [
    "## Plot the histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee86203f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(histogram.ravel())\n",
    "plt.title('Intensity histogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df67c25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.waitKey(0) # Wait for any keystroke in the window\n",
    "cv2.destroyWindow(\"Cells\") # Destroy the created window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0e3db2",
   "metadata": {},
   "source": [
    "A window will open:\n",
    "\n",
    "![OpenCV window](../opencv-cxx-load-display.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c04f771",
   "metadata": {},
   "source": [
    "## Binary threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0f464d",
   "metadata": {},
   "source": [
    "A lot of information about the various thresholds technique in OpenCV is available at [https://docs.opencv.org/master/db/d8e/tutorial_threshold.html](https://docs.opencv.org/master/db/d8e/tutorial_threshold.html) on OpenCV's website. We want the background in black, and the cells in white. We use the inverse of the binary threshold then. See `THRESH_BINARY_INV` in [https://docs.opencv.org/master/d7/d1b/group__imgproc__misc.html#gaa9e58d2860d4afa658ef70a9b1115576](https://docs.opencv.org/master/d7/d1b/group__imgproc__misc.html#gaa9e58d2860d4afa658ef70a9b1115576)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "348d998a",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_value = 70 # Taken from the histogram\n",
    "threshold_type = cv2.THRESH_BINARY_INV\n",
    "max_value = 255\n",
    "max_type = 4\n",
    "\n",
    "segmentated = cv2.threshold(image,\n",
    "          threshold_value,\n",
    "          max_value,\n",
    "          threshold_type)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22e6e5e",
   "metadata": {},
   "source": [
    "## Display the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f96b7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow(\"Cells\", cv2.WINDOW_GUI_EXPANDED); # Create a window\n",
    "cv2.imshow(\"Cells\", image) # Show our image inside the created window.\n",
    "\n",
    "cv2.namedWindow(\"Segmentation\", cv2.WINDOW_GUI_EXPANDED) # Create a window\n",
    "cv2.imshow(\"Segmentation\", segmentated) # Show our image inside the created window.\n",
    "\n",
    "cv2.waitKey(0) # Wait for any keystroke in the window\n",
    "cv2.destroyAllWindows() # Destroy all the created windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e1bb96",
   "metadata": {},
   "source": [
    "You'll see:\n",
    "\n",
    "![opencv-cxx-threshold1.png](../opencv-cxx-threshold1.png)\n",
    "\n",
    "which is not perfect. Remember mathematical morphology? Opening? Closing? Have a look at [https://docs.opencv.org/master/d3/dbe/tutorial_opening_closing_hats.html](https://docs.opencv.org/master/d3/dbe/tutorial_opening_closing_hats.html). \n",
    "\n",
    "And let's do some cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e80ec85",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3cb8c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "element = cv2.getStructuringElement(cv2.MORPH_CROSS,\n",
    "                                    (5, 5), \n",
    "                                    (2, 2))\n",
    "\n",
    "segmentated = cv2.morphologyEx(segmentated, cv2.MORPH_CLOSE, element);\n",
    "segmentated = cv2.morphologyEx(segmentated, cv2.MORPH_OPEN, element);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd354077",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow(\"Cells\", cv2.WINDOW_GUI_EXPANDED) # Create a window\n",
    "cv2.imshow(\"Cells\", image) # Show our image inside the created window.\n",
    "\n",
    "cv2.namedWindow(\"Segmentation\", cv2.WINDOW_GUI_EXPANDED) # Create a window\n",
    "cv2.imshow(\"Segmentation\", segmentated) # Show our image inside the created window.\n",
    "\n",
    "cv2.waitKey(0) # Wait for any keystroke in the window\n",
    "cv2.destroyAllWindows() # Destroy all the created windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cad344",
   "metadata": {},
   "source": [
    "You'll see:\n",
    "\n",
    "![opencv-cxx-threshold2.png](../opencv-cxx-threshold2.png)\n",
    "\n",
    "which is much better than the previous one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2f641e",
   "metadata": {},
   "source": [
    "## Apply the mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d2390e",
   "metadata": {},
   "source": [
    "The threshold provide a binary mask. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2d6b534",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_of_cells = cv2.bitwise_and(segmentated, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90adbaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow(\"Cells\", cv2.WINDOW_GUI_EXPANDED) # Create a window\n",
    "cv2.imshow(\"Cells\", image) # Show our image inside the created window.\n",
    "\n",
    "cv2.namedWindow(\"Segmentation\", cv2.WINDOW_GUI_EXPANDED) # Create a window\n",
    "cv2.imshow(\"Segmentation\", segmentated) # Show our image inside the created window.\n",
    "\n",
    "cv2.namedWindow(\"Just the cells\", cv2.WINDOW_GUI_EXPANDED) # Create a window\n",
    "cv2.imshow(\"Just the cells\", image_of_cells) # Show our image inside the created window.\n",
    "\n",
    "cv2.waitKey(0) # Wait for any keystroke in the window\n",
    "cv2.destroyAllWindows() # Destroy all the created windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b63cce",
   "metadata": {},
   "source": [
    "You'll see:\n",
    "\n",
    "![opencv-cxx-threshold3.png](../opencv-cxx-threshold3.png)\n",
    "\n",
    "The background has been removed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
